---
layout: post
title:  "经典模型SSD介绍"
data: 星期日, 15. 十二月 2019 01:38下午 
categories: 视觉
tags: 经典模型
---
* 本篇博客是对计算机视觉中一个经典模型SSD的介绍

# 计算机视觉经典模型--SSD
## 简单描述  ：
 SSD的全称为Single Shot MultiBox Detector，是一个one-stage的视觉模型。本文选取SSD300进行简单介绍

## 网络结构：
>这三张图一张张细化，后两张图都有一点小问题，第一张图严格来说priorbox的分支并不属于网络部分，是一种先验处理，后面我会讲，并且fc6和fc7起其实是卷积层而不是全连接层。第二张图来自http://www.mclover.cn/blog/index.php/archives/329.html，将网络更加细化，但是并没有将卷积层后面的激活函数以及Conv4_3之后的norm层给标出来，算是小问题。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-135056.png)


![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-134401.png)


![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-134336.png)


## 模型分析
### 优点：
1. 作为一个单阶段的检测器，比YOLO的速度更快，而检测的效果可以匹配Faster-RCNN

2.   使用了预测特征金字塔式的融合方式，从不同尺度的特征图下面来预测目标分类与位置，实现了不错的效果

3. 即使是分辨率比较小的图片也能产生不错的效果（相比Faster-Rcnn）

### 缺点：
1.  对小尺寸的目标识别仍比较差，还达不到Faster R-CNN的水准。这主要是因为小尺寸的目标多用较低层级的anchor来训练，较低层级的特征非线性程度不够，无法训练到足够的精确度。

2. 模型中有很多参数需要人工设置(在Prior box中)，这就导致调试的过程非常依赖经验。 

### 实验结果：

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191217-165208.png)




## 模型实现：
我的SSD网络模型参考的是https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py#L43，具体的网络结构在第一部分第三张图已经描绘的差不多了，这部分会介绍一下模型实现的一些其他细节。
### Prior Box

   这个即为网络结构中第二张图的右上角部分（也叫Defalut box），是一个先验的检测框处理。即对于每个点有多少个先验框，而网络的定位输出只是对这些这些先验框的一些小修正。
	
首先明确先验框的中心是feature map上每个点加上0.5,即比如为网络结构中第三张图，第一级检测的特征图最终是38x38的，那么就有38x38个中心点。
	
再说边长，对于每个中心点首先会产生一大一小两个正方形，小的正方形边长为![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-145849.png),大的正方形边长为![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-145750.png)
。然后会有很多个长方形，长方形的面积和小正方形面积一样，每个长宽比会产生两个长方形。长宽为：![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-150806.png) 和 ![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-150813.png)

第一个级会有一个长宽比，第二、三、四级有两个，第五级有一个，所以最后会得到（38x38x4 + 19x19x6 + 10x10x6 + 5x5x6 + 3x3x4 + 1x1x4）= 8732个prior box。

最后解释一下min_size和max_size，我们知道第一级的feature map大小是最大的，然后逐渐变小。而每一级的min_size和max_size都会发生变化。公式如下：

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-150338.png)

公式中m是使用feature map的数量（SSD 300中m=6）。第一层feature map对应的min_size=S1，max_size=S2；第二层min_size=S2，max_size=S3；其他类推。在原文中，Smin=0.2，Smax=0.9，但是在SSD 300中prior box设置并不能和paper中上述公式对应：

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-150507.png)



不过依然可以看出，SSD使用低层feature map检测小目标，使用高层feature map检测大目标，这也应该是SSD的突出贡献了。

**Prior Box** 是边长和中心点都是以百分比的形式给出，比如中心点在图的中间那么就是（0.5，0.5）

### 难样本挖掘（Hard Negative Mining）
我们知道对于一张图片来说肯定是负样本大大多于正样本，这样会使模型更加注重负样本，而我们的本意是想找到正样本，所以我们决定不取所有的负样本，而是只取置信度较高的负样本计算损失函数反向传播，使得正样本：负样本=1：3。

### 损失函数 
在介绍损失函数之前有三个东西需要先介绍一下

#### 第一个是**Smooth L1损失函数**，即更加光滑的L1损失函数。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-141033.png)

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-141105.png)

#### 第二个是真实框（ground truth）和预测框的**匹配策略** 确定正样本
我们在计算损失函数的时候需要对我们的每一个预测结果，即8732个prior box都进行判断，计算损失。那么这8732个prior box哪些属于负样本（背景），哪些属于正样本，又都属于哪些类就在这步决定。至于真实的值，我们在计算损失的时候并不会用到。

1. 首先寻找和每一个ground truth有最大IoU的预测框，保证每个ground truth都会有一个预测框与之匹配。

2. 然后SSD会将剩余的预测框与任意一个ground truth匹配，IoU大于阈值就认为是匹配上了（SSD300设置了是0.5）

3. 匹配到ground truth的预测框就是正样本，不然就是负样本，一个ground truth可能对应多个预测框。

#### 第三个是格式转换
  经过匹配策略之后，我们知道了8732个prior box都分别对应的是哪个真实框，或者是背景。但是需要计算损失我们还要将这些位置信息转化为网络的正确输出，毕竟网络不是直接输出目标框的位置的。
  
  ![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191217-104920.png)
其中 b 为真实值，d为prior box ，l为网络输出值
这是将网络输出转换为真实值，那么将真实值转化为网络输出就是这个的逆过程。

#### 损失函数定义
SSD的损失函数有两个部分组成，分别为**定位损失函数**和**分类损失函数**。
	
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191215-140603.png)


**注意：** ：
1. 只会为真实的正样本计算定位损失函数
2. N为正样本总数（一张图中所有prior box 为正样本的数量）
3. 分类损失函数对难样本挖掘出的负样本和正样本计算

#### 计算![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191217-104220.png)

由于在 64-bit 系统中，因为下溢(underflow) 和上溢(overflow) 的存在，

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191217-104338.png)

采取的技巧是：

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191217-104347.png)

一种典型的情况是：

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191217-104358.png)

这样保证了取指数的时候最大值为0．


### 模型测试
   当你要测试模型时，会对模型的输出格式进行转换并做阈值限定，删除一部分可信度较低的模型，并使用nms减少结果框，而在训练的时候我们不需要进行这些操作。
   
  同时网络的输出值并不是真实值，而是需要进行转换的，转换的方式同上一步的格式转换。
  



































