---
layout: post
title:  "虚拟内存"
data: 星期二, 10. 三月 2020 07:16下午 
categories: 操作系统
tags: 专题
---
* 该模块会针对操作系统中的某一块知识做专题整理，也许会有些不足或者错误的地方，未来可能会作修改。

#  操作系统专题5----内存管理之虚拟内存

## 为什么会有虚拟内存
在早期的计算机中，要运行一个程序，会把这些程序全都装入内存，程序都是直接运行在内存上的，也就是说程序中访问的内存地址都是实际的物理内存地址。当计算机同时运行多个程序时，必须保证这些程序用到的内存总量要小于计算机实际物理内存的大小。

但是程序规模的增长大于存储器容量的增长。我们想要理想的存储器，更大，更快，更便宜，非易失性存储。于是想到把硬盘的空间也用上(扮演内存的作用)，不常用的放在硬盘上，常用的放在内存上。


* 在讲虚拟内存之前 我要先讲一下覆盖和交换
## 覆盖与交换
### 覆盖

>
在较小的可用内存中运行较大的程序。

> #### 原理
>
把程序按照其自身逻辑结构，划分为若干个功能上相对独立的程序模块，那些不会同时执行的模块共享同一块内存区域，按时间先后来运行。
>
1.必要部分(常用功能)的代码和数据常驻内存，来管理数据的导入导出
>
2.可选部分(不常用功能)在其它程序模块中实现，平时存放在外存中，在需要时才装入内存。
>
3.不存在调用关系的模块不必同时装入内存，从而可以相互覆盖，即这些模块共用一个分区。

> #### 举个例子
>
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-200940.png)
>
A可以调用BC C可以调用EF

> #### 缺点
>
由程序员来把一个大的程序划分为若干个小的功能模块，并确定各个模块之间的覆盖关系，费时费力，增加了编程的复杂度。
>
覆盖模块从外存装入内存，是以时间换空间。

### 交换
>
多道程序在内存中时，让正在运行的程序或需要运行的程序获得更多的内存资源。

> #### 原理
>
1.可将暂时不能运行的程序送到外存，从而获得空闲内存空间。
>
2.操作系统把一个进程的整个地址空间的内容保存到外存中(换出swap out),而将将外存中的某个进程的地址空间读入到内存中(换入swap in)。换入换出内容大小为整个程序的地址空间。


> #### 会遇到的问题
>
1.交换时机的确定：只有当内存空间不够或有不够的危险时换出
>
2.交换区的大小：必须足够大以存放所有用户进程的所有内存映像的拷贝，必须能对这些内存映像进行直接存取
>
3.程序换入时的重定位：因为换出换入后的内存位置不一定相同，所以最好采用动态地址映射的方法

#### 覆盖与交换技术的比较
>
1.覆盖只能发生在那些(程序内)相互之间没有调用关系的程序模块之间，因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构。
>
2.交换技术是以在内存中的程序大小为单位来进行的，它不需要程序员给出各个模块之间的逻辑覆盖结构。
>
3.交换发生在内存中 程序 与 管理程序或操作系统 之间，而覆盖则发色会跟你在运行程序的内部。



## 虚存技术

虚拟内存结合了覆盖和交换

1.像覆盖技术那样，不是把程序的所有内容都放在内存中，因而能够运行比当前的空闲内存空间还要大的程序。但做得更好，能由操作系统自动完成，无需程序员介入.

2.像交换技术那样，能够实现进程在内存和外存之间的交换，因而获得更多的空闲内存空间。但能做得更好，只对进程的部分内容在内存和外存之间进行交换。


#### 前提要求：程序的局部性原理

指程序在执行过程中的一个较短时间，**所执行的指令地址和指令的操作数地址分别局限于一定区域**，表现为：

1.时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短的时间里

2.空间局部性：当前指令和领近的几条指令，当前访问的数据和领近的几个数据都集中在一个较小区域内

程序的局部性原理表明，从理论上来说，虚拟存储技术是能够实现的，而且在实现了以后应该能够取得一个满意的效果的。

> #### Linux下虚拟内存的结构图：
>
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-211958.png)
#### 虚拟内存的基本特征

1.**大的用户空间：**把物理内存和外存相结合，提供给用户的虚拟内存空间通常大于实际的物理内存，即实现了着两者的分离。

2.**部分交换：**与交换技术相比，虚拟存储的调入调出是对部分虚拟地址空间进行的。

3.**不连续性：**物理内存分配的不连续，虚拟地址空间使用的不连续（中间一部分可能会被换出去，所以不连续）

#### 基于页式或者段式的虚拟内存管理
在装入程序时，不必将其全部装入内存，只装入当前执行的部分页面或段装入内存。

如果需要指向的指令或者访问的数据不在内存（称为缺页或者缺段），则由处理器通知操作系统将相应的页面或段调入内存，然后继续执行程序。同时，操作系统将内存中暂时不用的页面或者段调出到外存上，省出空间。



## 虚拟页式内存管理

大部分虚拟存储系统都采用虚拟页式存储管理技术，即在页式存储管理的基础上，增加请求调页和页面置换功能。

缺页的时候有内存就用**请求调页**。

没有空闲空间就用**页面置换**。

当一个用户程序要调入内存运行，不是将该程序的所有页面装入内存，而是指装入部分页面，就可启动程序运行。如果运行时发现需要的数据不在内存，就发出缺页的中断，系统在处理这个中断时，将外存中相应页面调入内存，使得该程序能继续运行。

#### 地址转换（和内存管理里面的差不多）

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-213910.png)

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-214000.png)

## 页面置换算法

当缺页中断发生要调入新的页面并且内存已满，则选择内存中哪个物理页面被置换。目标是尽可能地减少页面的换进换出次数

#### 最优页面置换算法
每次置换换出距离下次访问最久的页面换出，最优情况，无法实现，但是可以作为标准

#### 先进先出算法（FIFO）
性能较差，调出的页面可能是经常访问的页面。FIFO很少单独使用。有Belady现象，页帧容量越高反而缺页越多。

**优点：**
先进先出算法实现简单，是最直观的一个算法，认为最早进来的应该最应该被置换。

**缺点：**完全没考率访问情况，如果较早进来但是访问频率较高就不该被换成出，实际应用效果也比较差。
#### 最近最久未使用算法（LRU）
依据是程序的局部性原理

记录各个页面使用的先后顺序

方法一：维护一个页面链表，刚使用过的是头节点，最久的是尾节点。如果要访问的节点在链表中，就要把它移到链首。

方法二：使用栈

**优点：**
由于考虑程序访问的时间局部性，一般能有较好的性能；实际应用多

**缺点：**
实现需要较多的硬件支持，会增加硬件成本

#### 时钟页面置换算法（CLOCK）

与LRU近似，是对FIFO的改进，用这个算法更实际

当页被访问过used bit会置1，所以认为used bit未0就是很久没访问的。 

用环型链表维护，循环找第一个used bit为0的页，如果找到是1的，就置0，然后找下一个

#### 二次机会法
Clock的升级，原来只会看used bit，现在还看dirty bit（是否被写过）

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-204102.png)

#### 最不常用算法（LFU）
选择被访问次数最少的页面换出

只考虑了访问次数 ，没考虑时间因素，比如有个数据一段时间用了很多次，之后再也不用了，不被换出去就离谱，所以就需要定期减少被访问次数，右移一位（除以2）

LFU 算法本质上可以看做是一个 top K 问题(K = 1)，即选出频率最小的元素，因此我们很容易想到可以用二项堆来选择频率最小的元素，这样的实现比较高效。最终实现策略为小顶堆+哈希表。

#### 缺页率页面置换算法

可以使用缺页率算法（PFF）动态调整常驻集大小，性能好但是增加了系统开销。
根据缺页率调整工作集窗口，也就是常驻集的大小。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-215028.png)

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-215033.png)

#### Belady现象

在采用FIFO的算法，有时候分配的物理页面增加，缺页率反而增加。
因为FIFO算法的置换特征与进程访问内存的动态特征是矛盾的。
只看了页存在的时间没有看访问的情况

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-205931.png)

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-205936.png)

LRU满足栈算法的特点，所以不会出现Belady现象。 

>
LRU当中替换的是使用频率最低的页，留下的都是使用频率高的页。当实页数增加，能够留下的高频访问的页也就更多，这直接关系到命中率的增加。
>
先进先出的替换算法，完全不考虑使用频率，即使增加了实页数，多贮存的部分接下来常访问可能性也不一定大（看运气），也就并不一定能增加命中率。



#### 局部性原理的衡量标准
是所有页面置换算法的前提，使用工作集来验证是否满足局部性原理。

>
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-211302.png)
>
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-211308.png)
>
t2的局部性比t1的局部性要好
>
所以随着时间推移局部性会发生变化，我们希望针对不同的局部性采用不同的页面算法。



#### 抖动问题

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-211825.png)

工作集是程序正在使用的页面集合，常驻集则是留在内存的页面集合，正在使用的不一定在内存中。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-211356.png)

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-211453.png)

程序开的多，OS忙于换进换出的I/O操作，用于运行程序的cpu少了。找到交汇点，MTBF==PFST，此时可以并发执行的程序个数和cpu利用率都较好，总体达到平衡。

## 虚拟内存的性能分析
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200310-214237.png)

如果程序有局部性特点，p就会非常小

q的情况就是你对这个内存进行了写操作，除了读进来的5ms，你还要把它换出去，还要5ms。

## 虚拟内存大小设置

虚拟内存为什么只能设为物理内存的1.5-2倍？

如果虚拟内存开得过大，那么windows就会更多的使用虚拟内存，
这也就意味着频繁的硬盘操作，而硬盘操作可比内存操作慢很多，

虚拟内存设置太大的话,物理内存就会有闲置,而虚拟内存速度又不如物理内存,那么你的程序运行速度就会减慢.


## 如果内存够大了还需要虚拟内存吗？
答案是需要

因为虚拟内存不单单是备用那么简单，很多时候，Windows系统需要利用虚拟内存执行一些特定的操作，提高内存的命中率和系统的稳定性

因为Windows操作系统中虚拟内存承载了许多超出页面文件功能以外的功能。

## 虚拟内存的优缺点

#### 优点：
>
（1）可以使用有限的内存资源，处理比实际内存更大的文件或者数据
>
（2）更加高效的内存利用
>
（3）在有限的内存资源内，让系统运行更多的程序实例，因为每个程序都是按需取。

#### 缺点：
>
（1）如果内存严重不足，而处理超级大的文件时，会频繁引起内存和磁盘进行swap，从而降低系统性能。
>
（2）在多个应用程序之间切换会花费更多的时间
>
（3）虚拟内存本质上是充分了磁盘空间，但同时变相的提供用户使用的实际磁盘空间也会变小。







































