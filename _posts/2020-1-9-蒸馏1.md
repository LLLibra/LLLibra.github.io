---
layout: post
title: "模型压缩-蒸馏篇"
data: 星期四, 09. 一月 2020 08:20下午 
categories: 模型压缩
tags: 知识蒸馏
---
# 《Distilling the Knowledge in a Neural Network》



* 作为蒸馏篇的第一篇，我准备介绍一篇蒸馏的经典论文，发布于14年的NIPS，在Google学术上有着2000+的引用。同时我会整理一些有关蒸馏的基础知识

## 基本概念
蒸馏的简单概念就是将一个复杂网络的输出让一个小网络学习，比如猫和狗有一些共同点（都是四只脚），仅仅根据真实标签很难学到这些，但是通过将一个复杂的网络输出设置为标签就可以告诉你，这个物体虽然是猫，但是也有点像狗，而不是那么绝对。

蒸馏可以有多种选择，可以对网络的最后输出进行蒸馏（本文就是），也可以对中间层，也可以基于元学习。

## 简单介绍
  这种方法感觉受到了ensemble的启发，利用大型（teacher net）网络提取先验知识，将这种先验知识作为soft target让微型网络（student network）学习,有点像Boost中第一个分类器学到后调整weight让第二个分类器学习，当然相似中也有不同之处。

## 基础结构
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200109-204218.png)

* cumbersome model：复杂的大模型（教师网络）
* distilled model：经过knowledge distillation后学习得到的小模型（学生网络）
* hard targets：输入数据所对应的label（真实标签）
* soft targets：输入数据通过大模型（cumbersome model）所得到的softmax层的输出（教师网络的输出）

## 模型结构

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200109-205119.png)

* 先用hard target，也就是正常的label训练大模型。
* 利用训练好的大模型来计算soft target。也就是大模型“软化后”再经过softmax的output。

* 在小模型的基础上再加一个额外的soft target的loss function，通过lambda来调节两个loss functions的比重


#### 温度T
直接使用teacher网络的softmax的输出结果不大合适。一个网络训练好之后，对于正确的答案会有一个很高的置信度。例如，在MNIST数据中，对于某个2的输入，对于2的预测概率会很高，而对于2类似的数字，例如3和7的预测概率极小。这样的话，teacher网络学到数据的相似信息（例如数字2和3，7很类似）很难传达给student网络。由于它们的概率值接近0。因此，文章提出了温度T。

这里T是超参数，文中说是‘温度’，经过该参数之后的softmax会更加平滑，分布更加均匀而大小关系不变。T参数在设置为1的时候就是平常的softmax函数。

在知识转换阶段，设置复杂网络与简易网络相同的T参数。在此之后再从新将T设置为1

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200109-205424.png)
 
![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200110-201936.png)

## 实际应用
  当数据集非常巨大以及模型非常复杂时，训练多个模型所需要的资源是难以想象的，因此提出一种新的集成模型方法，包括：

* 一个 Generalist model ：使用全部数据进行训练
* 多个 Specialist models ：对某些易混淆的类别进行专门训练的专有模型

  Specialist models 的训练集中，一半是初始训练集中某些特定类别的子集（special subset），另一半由剩余初始训练集中随机采样组成

    在该方法中，只有 generalist model 耗时较长，剩余的 specialist model 由于训练数据较少，且相互独立，可以并行训练，因此整体运算量少了非常多。



    但是，specialist model由于只使用特定类别的数据进行训练，因此模型对别的类别的判断能力几乎为0，导致非常容易过拟合，我们可以采用如下方法来解决：

当 specialist model 通过 hard targets 训练完成后，再使用由 generalist model 生成的 soft targets 进行 finetune，这样做是因为 soft targets 保留了一些对于其他类别数据的信息，因此模型可以在原来基础上学到更多知识，有效避免了过拟合


![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20200110-202254.png)
 