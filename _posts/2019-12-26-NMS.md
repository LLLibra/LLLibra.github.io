---
layout: post
title:  "NMS介绍"
data: 星期四, 19. 十二月 2019 03:57下午 
categories: 视觉
tags: 基础结构
---
* 本篇博客是对计算机视觉模型中经常使用到的结构NMS的一个介绍和总结。

# 计算机视觉经典结构--NMS(非极大值抑制)
### 作用：
对于熟悉目标检测的人都知道，对于一个目标在网络中并不是只会识别出一个结果（目标框），但是我们输出的时候一个物体确只有一个框，这就是NMS起的作用。
>
简单来说NMS就是尽量将最符合真实目标的框给留下来，而将该目标的其他框的去除。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191226-195906.png)

### 过程
先假设有6个矩形框，根据分类器的类别分类概率做排序，假设从小到大属于人物的概率 分别为A、B、C、D、E、F。

(1)从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值;
    

(2)假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。
      

 (3)从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。


就这样一直重复，找到所有被保留下来的矩形框。


![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191226-200642.png)


### 问题
当需要检测的物体分的很开时，NMS并不会产生什么问题，但是当两个需要检测的物体离的很近时，就很容易将其中一个真实的目标框去除而产生漏检。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191226-195825.png)

### 改进（soft-NMS）
不要粗鲁地删除所有IOU大于阈值的框，而是降低其置信度。

soft NMS算法的大致思路为：M为当前得分最高框，bi 为待处理框，bi 和M的IOU越大，bi 的置信度si 就下降的越厉害。

![](https://github.com/LLLibra/LLLibra.github.io/raw/master/_posts/imgs/20191226-200052.png)

#### NMS其实还有很多变种，但大多用于NLP中





